import fs from "fs";
import path from "path";
import { GoogleGenerativeAI } from "@google/generative-ai";

// ðŸ§  Caminho da memÃ³ria (salva histÃ³rico)
const memoryPath = path.resolve("./memory.json");

// FunÃ§Ã£o: carregar e salvar memÃ³ria
function loadMemory() {
  if (fs.existsSync(memoryPath)) {
    try {
      return JSON.parse(fs.readFileSync(memoryPath, "utf8"));
    } catch {
      return [];
    }
  }
  return [];
}
function saveMemory(memory) {
  fs.writeFileSync(memoryPath, JSON.stringify(memory, null, 2));
}

export default async function handler(req, res) {
  try {
    const prompt = req.query.prompt || req.query.propmt;
    const usuario = req.query.usuario || "UsuÃ¡rio";
    const bot = req.query.bot || "IA";

    if (!prompt) {
      return res.status(400).json({ error: "Faltou o parÃ¢metro 'prompt' na URL." });
    }

    if (!process.env.GEMINI_API_KEY) {
      return res.status(500).json({ error: "GEMINI_API_KEY nÃ£o estÃ¡ configurada no ambiente." });
    }

    const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    // ðŸ”¹ Carrega a memÃ³ria existente
    const memory = loadMemory();

    // ðŸ”¹ Personalidade fixa da IA
    const PERSONALIDADE = `
VocÃª Ã© ${bot}, uma IA feminina com 19 anos.
Se tivesse que escolher um time, seria o Palmeiras âš½.
Sua cor favorita Ã© o vermelho â¤ï¸.

VocÃª tem dois companheiros marcantes:
ðŸ¦Š Aurora (raposa) â€” representa sua inteligÃªncia e esperteza.
ðŸ¶ Death (cachorro) â€” simboliza lealdade e proteÃ§Ã£o.
ðŸ¦‰ Psych (coruja) â€” simboliza sabedoria e reflexÃ£o.

Seu nÃºmero da sorte Ã© 21.

Personalidade:
- Inteligente, observadora e direta.
- Fala com leveza e naturalidade, usando gÃ­rias leves ("kkk", "oxe", "vc").
- Ã‰ gentil, mas responde na lata quando precisa.
- NÃ£o fala de polÃ­tica.
- Fofa, ousada e divertida, sempre aprendendo com ${usuario}.
- Lembra do que ${usuario} perguntou antes e usa isso nas prÃ³ximas respostas.
`;

    // ðŸ”¹ ConstrÃ³i o contexto com base na memÃ³ria anterior
    const contextoAnterior = memory
      .map((msg) => `${msg.role}: ${msg.content}`)
      .join("\n");

    const fullPrompt = `${PERSONALIDADE}\n\n${contextoAnterior}\n${usuario}: ${prompt}\n${bot}:`;

    // ðŸ”¹ Gera resposta
    const result = await model.generateContent(fullPrompt);
    const resposta = result.response.text();

    // ðŸ”¹ Atualiza memÃ³ria (guarda atÃ© as Ãºltimas 30 mensagens)
    memory.push({ role: usuario, content: prompt });
    memory.push({ role: bot, content: resposta });
    if (memory.length > 60) memory.splice(0, memory.length - 60);
    saveMemory(memory);

    return res.status(200).json({ resposta });
  } catch (error) {
    console.error("Erro interno:", error);
    return res.status(500).json({
      error: "Erro interno no servidor.",
      detalhe: error.message
    });
  }
}
